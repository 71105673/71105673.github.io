---
title: "Day-6 CNN" 
date: "2025-06-30"
thumbnail: "../../../assets/img/ARM/AI/image copy 32.png"
---

# CNN ì´ë€?
***Convolutional Neural Network(í•©ì„±ê³± ì‹ ê²½ë§)***
-ì´ë¯¸ì§€ ì¸ì‹, ì˜ìƒ ë¶„ì„, ìì—°ì–´ ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¡°.

## ğŸ“Œ CNNì˜ í•µì‹¬ ê°œë…

| êµ¬ì„± ìš”ì†Œ                              | ì„¤ëª…                                                     |
| ---------------------------------- | ------------------------------------------------------ |
| **Convolution Layer (í•©ì„±ê³±ì¸µ)**       | í•„í„°(ë˜ëŠ” ì»¤ë„)ë¥¼ ì‚¬ìš©í•´ ì…ë ¥ ì´ë¯¸ì§€ì˜ íŠ¹ì§•(Feature)ì„ ì¶”ì¶œí•¨. ê°€ì¥ í•µì‹¬ì ì¸ ì¸µ.    |
| **Activation Function (í™œì„±í™” í•¨ìˆ˜)**   | ì£¼ë¡œ ReLU(Rectified Linear Unit)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ì„ í˜•ì„±ì„ ì¶”ê°€í•¨.        |
| **Pooling Layer (í’€ë§ì¸µ)**            | íŠ¹ì„± ë§µì„ ì¶•ì†Œí•´ ì—°ì‚°ëŸ‰ ê°ì†Œ ë° ì¤‘ìš”í•œ íŠ¹ì§• ìœ ì§€ (MaxPoolingì´ ì¼ë°˜ì ).        |
| **Fully Connected Layer (ì™„ì „ ì—°ê²°ì¸µ)** | ì¶”ì¶œëœ íŠ¹ì§•ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ë¥˜ë‚˜ ì˜ˆì¸¡ ë“±ì„ ìˆ˜í–‰. ë§ˆì§€ë§‰ì— Softmax ë˜ëŠ” Sigmoid ì‚¬ìš©. |

## ğŸ“Š CNN vs ì¼ë°˜ MLP (ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ )

| í•­ëª©     | CNN                 | MLP       |
| ------ | ------------------- | --------- |
| íŠ¹ì§• ì¶”ì¶œ  | ìë™ìœ¼ë¡œ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ      | ìˆ˜ë™ í˜¹ì€ ì œí•œì  |
| ì…ë ¥ êµ¬ì¡°  | ì£¼ë¡œ ì´ë¯¸ì§€/2D ë°ì´í„°       | 1ì°¨ì› ë²¡í„°    |
| íŒŒë¼ë¯¸í„° ìˆ˜ | ìƒëŒ€ì ìœ¼ë¡œ ì ìŒ (ê³µìœ  í•„í„° ì‚¬ìš©) | ë§¤ìš° ë§ìŒ     |

## CNN ëª¨ë¸ì˜ êµ¬ì„±

![alt text](../../../assets/img/ARM/AI/CNN/image.png)

>ì²˜ìŒ ì…ë ¥ì€ 32Ã—32Ã—3ì˜ 3ì°¨ì› ë°ì´í„°ì´ë‹¤. 
>
>í•œ ë²ˆì˜ í•©ì„±ê³± ì¸µì„ ê±°ì³ 28Ã—28Ã—6ì¸ í¬ê¸°ì˜ 3ì°¨ì› ë°ì´í„°ê°€ ë˜ì—ˆë‹¤.

>CNN Layerì—ëŠ” í•©ì„±ê³±ì´ 6ë²ˆ(6ê°œì˜ í•„í„°) ì‚¬ìš©ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. 
>
>ë‹¤ìŒìœ¼ë¡œ Pooling layerë¥¼ ê±°ì³ 14Ã—14Ã—6ì¸ í¬ê¸°ì˜ ë°ì´í„°ê°€ ë˜ì—ˆë‹¤.

>ì´ê²ƒì„ ë²¡í„°í™”(Flatten)í•¨ìœ¼ë¡œì¨ 1,176 í¬ê¸°ì˜ 1ì°¨ì› ë²¡í„°ê°€ ëœë‹¤.
>
>ë§ˆì§€ë§‰ìœ¼ë¡œ FC layerë¥¼ ê±°ì³ ìµœì¢…ì ìœ¼ë¡œ class ê°œìˆ˜ì— .ë§ë„ë¡ 10ê°œì˜ ê°’ì„ ê°–ëŠ” ì¶œë ¥ì¸µì´ ë§Œë“¤ì–´ì§„ë‹¤.

### CNN êµ¬ì„± ìš”ì†Œ -> Convolutuon Layer ì—°ì‚°

![alt text](<../../../assets/img/ARM/AI/CNN/image copy.png>)

>í•©ì„±ê³±ì€ í…ì„œ(tensor)ì™€ í…ì„œ ì‚¬ì´ì—ì„œ ì •ì˜ë˜ëŠ”
ì—°ì‚°ì´ë‹¤.

>í…ì„œëŠ” ì°¨ì›ì— ë”°ë¼ 0ì°¨ì›ì€ scalar, 1ì°¨ì›ì€ ë²¡í„°,
2ì°¨ì›ì€ í–‰ë ¬, 3ì°¨ì›ì€ 3ì°¨ì› í–‰ë ¬(í…ì„œ)ë¼ê³ 
ë¶€ë¥¸ë‹¤.

>4ì°¨ì› í…ì„œì˜ ê²½ìš° 4ì°¨ì› ë²¡í„°ì²˜ëŸ¼ ìˆ˜ì‹ìœ¼ë¡œë§Œ
í‘œí˜„ë˜ë©°, ë³´í†µ 3ì°¨ì› í…ì„œ(ë˜ëŠ” ì´ë¯¸ì§€)ê°€ ì—¬ëŸ¬ ê°œ
ëª¨ì—¬ ìˆë‹¤ëŠ” ì˜ë¯¸ê°€ ëœë‹¤.

### í•©ì„±ê³± ê³„ì‚°

![alt text](<../../../assets/img/ARM/AI/CNN/image copy 2.png>)

>ì°¨ì›ì˜ í¬ê¸°ê°€ ê°™ì€ ë‘ í…ì„œë¥¼ ê³„ì‚°í•´ Scalar ê°’ì´ ë˜ëŠ” ì—°ì‚°

### Filter 
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 3.png>)
> íŠ¹ì • ì‚¬ì´ì¦ˆì˜ í…ì„œë¥¼ ì‚¬ìš©í•´ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ìŠ¤ìº”í•˜ë“¯ì´ ì´ë™ì—°ì‚°

> ì´ë•Œ ìŠ¤ìº”í•˜ëŠ” í…ì„œë¥¼ í•„í„°ë¼ í•œë‹¤.

### Feature Map
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 4.png>)

- ì…ë ¥ ë°ì´í„°ì— í•„í„°ë¡œ ìŠ¤ìº”í•œ ê²°ê³¼ë¡œ ë§Œë“¤ì–´ì§€ëŠ” ì¶œë ¥ í…ì„œë¥¼ feature map(íŠ¹ì„±
ë§µ)ì´ë¼ í•œë‹¤.

- ë³´í†µ í•˜ë‚˜ì˜ í•©ì„±ê³± ì¸µì—ì„œ ì—¬ëŸ¬ ê°œì˜ í•„í„°ê°€ ì‚¬ìš©ë˜ë©°, ê·¸ ê²°ê³¼ë¡œ í•„í„° ìˆ˜ë§Œí¼ì˜ íŠ¹ì„± ë§µì´ ë§Œë“¤ì–´ì§„ë‹¤.

- í•©ì„±ê³± ì—°ì‚° í›„ì— í™œì„±í™” í•¨ìˆ˜ë¥¼ ì ìš©í•˜ëŠ”ë° ì´ê²ƒì€ íŠ¹ì„± ë§µì´ ë§Œë“¤ì–´ì§„ í›„ì— ì‘ìš©í•œë‹¤.

- íŠ¹ì„± ë§µì— í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‘ìš©ì‹œì¼œ ë§Œë“¤ì–´ì§„ ê²°ê³¼ë¥¼ activation mapì´ë¼ê³ ë„ í•œë‹¤.

- CNNì˜ ë‹¤ìŒ ì¸µì—ì„œëŠ” ê³„ì‚°ëœ activation mapë“¤ì„ ëª¨ì•„ í•˜ë‚˜ì˜ í…ì„œë¡œ ë§Œë“¤ì–´ì„œ ìƒˆë¡œìš´ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. 

- ì˜ˆë¥¼ ë“¤ì–´ activation mapì˜ í¬ê¸°ê°€ 28Ã—28ì´ê³  ì‘ìš©í•œ
í•„í„°ì˜ ê°œìˆ˜ê°€ 5ê°œì˜€ë‹¤ë©´, ë‹¤ìŒ ì…ë ¥ ë°ì´í„°ëŠ” 28Ã—28Ã—5ì˜ í¬ê¸°ê°€ ëœë‹¤. 
- ì—¬ê¸°ì„œ activation mapê³¼ íŠ¹ì„± ë§µì€ ê°™ì€ í¬ê¸°ì´ë‹¤.

- ê·¸ë¦¼ì„ ì‚´í´ë³´ë©´, ì…ë ¥ ì´ë¯¸ì§€ê°€ 32Ã—32Ã—3ì´ê³  í•˜ë‚˜ì˜ í•„í„°ë¥¼ í†µí•´ 28Ã—28Ã—1 í¬ê¸°ë¥¼ ê°–ëŠ” í•˜ë‚˜ì˜ íŠ¹ì„± ë§µì´ ë§Œë“¤ì–´ì§€ë©°, ì—¬ê¸°ì— activation function(ì˜ˆ: ReLU)ì´ ì‘ìš©í•´ ê°™ì€ í¬ê¸°ì˜ activation mapì´ ë§Œë“¤ì–´ì§„ë‹¤.

### Stride
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 5.png>)
> CNN ê³¼ì •ì—ì„œ í•©ì„±ê³± ì—°ì‚°ì— í•„í„°ê°€ ì›€ì§ì´ëŠ” ê°„ê²©

> í•©ì„±ê³±ì´ 2ì°¨ì›(3x3) ìœ¼ë¡œ ì •ì˜ ë”°ë¼ì„œ Strideë„ 2ì°¨ì›(m, n)ìœ¼ë¡œ ì •ì˜

> í•œ ë²ˆ í•©ì„±ê³± ì—°ì‚°ì„ í•œ í›„ì— ìš°ì¸¡ìœ¼ë¡œ më§Œí¼ì”© ì´ë™í•´ ì…ë ¥ í…ì„œì˜ ëê¹Œì§€
ì´ë™í•œ í›„, ì•„ë˜ë¡œ në§Œí¼ì”© ì›€ì§ì—¬ì„œ ë§¨ ì™¼ìª½ë¶€í„° ë‹¤ì‹œ ìŠ¤ìº”í•˜ëŠ” ë°©ì‹ì´ë‹¤.

### Padding

![alt text](<../../../assets/img/ARM/AI/CNN/image copy 6.png>)

> í•©ì„±ê³± ì—°ì‚°ì´ íŠ¹ì„± ë§µì€ ê¸°ì¡´ ë°ì´í„° í¬ê¸°ë³´ë‹¤ ì‘ì•„ì§„ë‹¤.

>íŒ¨ë”©ì„ ë§ëŒ€ì–´ ì¶œë ¥ í¬ê¸°ë¥¼ ì…ë ¥ í¬ê¸°ì™€ ê°™ê²Œ ë§Œë“¤ë©° ë¹ˆë„ìˆ˜ë¥¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.

> í•©ì„±ê³± ì¸µì—ì„œ ì¸ìˆ˜ ì„¤ì •ì„ Padding = sameìœ¼ë¡œ ì‚¬ìš©

### í™œì„±í™” (Activation)

- í•©ì„±ê³± ì—°ì‚° í›„, ì‹ ê²½ë§ì²˜ëŸ¼ í™œì„±í™” í•¨ìˆ˜(ReLU ë“±) ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ì„ í˜•ì„±ì„ ë¶€ì—¬í•¨.
  
- ì¼ë°˜ì ìœ¼ë¡œ ReLU ë˜ëŠ” ReLU ë³€í˜• í•¨ìˆ˜ë¥¼ ì‚¬ìš©.
  
- ì´ëŸ¬í•œ ì²˜ë¦¬ ê³¼ì •ì€ ê¸°ì¡´ ì‹ ê²½ë§ê³¼ ë™ì¼í•¨.
  
- í•©ì„±ê³± ì¸µ ê°œìˆ˜ëŠ” ì„¤ì •ì— ë”°ë¼ ë‹¬ë¼ì§ (1ê°œë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ 2~3ê°œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ).
  
- ê° í•©ì„±ê³± ì¸µ ë’¤ì— Pooling Layerë¥¼ ë¶™ì´ê¸°ë„ í•¨.
  
- ì—¬ëŸ¬ ìœ ëª…í•œ ì‹ ê²½ë§ êµ¬ì¡°(Architecture)ë¥¼ ì°¸ê³ í•˜ë©´ ë” ì¢‹ì€ ëª¨ë¸ì„ ì„¤ê³„í•˜ëŠ” ë° ë„ì›€ë¨. (ì˜ˆ: VGG, ResNet ë“±)


### Polling Layer

Max
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 7.png>)

Average
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 8.png>)

Global Average
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 9.png>)

>í•©ì„±ê³± ì—°ì‚°ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ í•˜ë‚˜ì˜ íŠ¹ì„± ë§µì—ì„œ í‰ê· ê°’ì„ ì¶œë ¥í•˜ëŠ” Pooling.

>ì´ì „ì˜ Pooling ê³„ì‚°ë³´ë‹¤ í¬ê¸°ë¥¼ ë§ì´ ì¤„ì´ê²Œ ëœë‹¤.

>GoogLeNetì—ì„œ FC Layer ì§ì „ì— Flatten ëŒ€ì‹  ì‚¬ìš©í•¨.



# ì‹¤ìŠµ

## ìˆ˜ë™êµ¬í˜„
```python
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# í•©ì„±ê³± í•¨ìˆ˜ êµ¬í˜„
def conv(a, b): 
    c = np.array(a) * np.array(b)
    return np.sum(c)

# MaxPolling í•¨ìˆ˜ êµ¬í˜„
def MaxPooling(nimg): 
    ning = np.array(nimg)
    i0, j0 = ning.shape
    i1 = int((i0 + 1) / 2)
    j1 = int((j0 + 1) / 2)

    output = np.zeros((i1, j1))

    if i0 % 2 == 1:
        i0 += 1
        tmp = np.zeros((1, j0))
        ning = np.concatenate((ning, tmp), axis=0)

    if j0 % 2 == 1:
        j0 += 1
        tmp = np.zeros((i0, 1))
        ning = np.concatenate((ning, tmp), axis=1)

    for i in range(output.shape[0]):
        for j in range(output.shape[1]):
            a = ning[2 * i:2 * i + 2, 2 * j:2 * j + 2]
            output[i, j] = a.max()
    return output

# í•©ì„±ê³± ì¶œë ¥ ì¸µ (Feature Map) í•¨ìˆ˜ êµ¬í˜„ 
def featuring(nimg, filters):
    feature = np.zeros((nimg.shape[0] - 2, nimg.shape[1] - 2))
    for i in range(feature.shape[0]):
        for j in range(feature.shape[1]):
            a = nimg[i: i + 3, j: j + 3]
            feature[i, j] = conv(a, filters)
    return feature

# MaxPooling ì¶œë ¥ ì¸µ í•¨ìˆ˜ êµ¬í˜„ (ì—¬ëŸ¬ map ê³„ì‚°)
def Pooling(nimg):
    nimg = np.array(nimg)
    pool0 = []
    for i in range(len(nimg)):
        pool0.append(MaxPooling(nimg[i]))
    return pool0

# ë°°ì—´ì„ ê·¸ë¦¼ìœ¼ë¡œ ë³€í™˜
def to_img(nimg):
    nimg = np.array(nimg)
    nimg = np.uint8(np.round(nimg))
    fimg = []
    for i in range(len(nimg)):
        fimg.append(Image.fromarray(nimg[i]))
    return fimg

# Feature map ìƒì„± (ì—¬ëŸ¬ ê°œì˜ Filter ê³„ì‚°)
def ConvD(nimg, filters):
    nimg = np.array(nimg)
    feat0 = []
    for i in range(len(filters)):
        feat0.append(featuring(nimg, filters[i]))
    return feat0

# ReLU êµ¬í˜„
def ReLU(fo):
    fo = np.array(fo)
    fo = (fo > 0) * fo
    return fo

# Conv+ReLU+MaxPooling
def ConvMax(nimg, filters):
    nimg = np.array(nimg)
    f0 = ConvD(nimg, filters)
    f0 = ReLU(f0)
    fg = Pooling(f0)
    return f0, fg

# í•©ì„±ê³± í›„ì˜ ìƒíƒœì™€ MaxPooling í›„ì˜ ìƒíƒœë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë¦¬ê¸°
def draw(f0, fg0, size=(12, 8), k=-1):
    plt.figure(figsize=size)
    for i in range(len(f0)):
        plt.subplot(2, len(f0), i + 1)
        plt.gca().set_title('Conv' + str(k) + '-' + str(i))
        plt.imshow(f0[i])
    for i in range(len(fg0)):
        plt.subplot(2, len(fg0), i + len(f0) + 1)
        plt.gca().set_title('MaxP' + str(k) + '-' + str(i))
        plt.imshow(fg0[i])
    if k != -1:
        plt.savefig('conv' + str(k) + '.png')
    plt.show()

# 3ê°œì˜ activation map í•©ì¹˜ê¸°
def join(mm):
    mm = np.array(mm)
    m1 = np.zeros((mm.shape[1], mm.shape[2], mm.shape[0]))
    for i in range(mm.shape[1]):
        for j in range(mm.shape[2]):
            for k in range(mm.shape[0]):
                m1[i][j][k] = mm[k][i][j]
    return m1

# ê³¼ì •ì„ ê³„ì‚°í•˜ê³  ê²°ê³¼ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ì¶œë ¥
def ConvDraw(p0, filters, size=(12, 8), k=-1):
    f0, fg0 = ConvMax(p0, filters)
    f0_img = to_img(f0)
    fg1_img = to_img(fg0)
    draw(f0, fg0, size, k)
    p1 = join(fg0)
    return p1

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
nimg31 = np.random.rand(10, 10)
filters = [np.ones((3, 3))] * 3

m0 = ConvDraw(nimg31, filters, (12, 10), 0)
```
## ê²°ê³¼
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 10.png>)


# ì‹¤ìŠµ CIFAR10_CNN
```python
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10

(train_x, train_y), (test_x, test_y) = cifar10.load_data()

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

train_x = train_x / 255.
test_x = test_x / 255.

from tensorflow.keras.utils import to_categorical

train_y = to_categorical(train_y)
test_y = to_categorical(test_y)

# CNN ëª¨ë¸ ë””ìì¸
from tensorflow.keras import models, layers

model = models.Sequential()

# (32, 32, 3) => (30, 30, 32)
model.add(layers.Conv2D(filters=32, kernel_size=(3, 3),
                        activation='relu',
                        input_shape=(32, 32, 3)))
# (30, 30, 32) => (15, 15, 32)
model.add(layers.MaxPool2D(pool_size=(2, 2)))

# (15, 15, 32) => (13, 13, 64)
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),
                        activation='relu'))

# (13, 13, 64) => (6, 6, 64)
model.add(layers.MaxPool2D(pool_size=(2, 2)))

# (6, 6, 64) => (4, 4, 64)
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),
                        activation='relu'))

# 3Dë¥¼ 1Dë¡œ ë³€í™˜
model.add(layers.Flatten())

# Classification : Fully Connected Layer ì¶”ê°€
model.add(layers.Dense(units=64, activation='relu'))
model.add(layers.Dense(units=10, activation='softmax'))

# ëª¨ë¸ì˜ í•™ìŠµ ì •ë³´ ì„¤ì •
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

# ëª¨ë¸ í•™ìŠµ
history = model.fit(x=train_x, y=train_y, epochs=20, batch_size=256, verbose=2, validation_split=0.2)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()
```
### ê²°ê³¼
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 11.png>)

```python
plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_x[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays,
    # which is why you need the extra index
    plt.xlabel(class_names[train_y[i].argmax()])
plt.show()
```
### ê²°ê³¼
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 12.png>)

![alt text](<../../../assets/img/ARM/AI/CNN/image copy 13.png>)

```python
print(f'í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(train_x)}ì¥')
print(f'í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜: {len(test_x)}ì¥')
print(f'ì´ ë°ì´í„° ìˆ˜: {len(train_x) + len(test_x)}ì¥')
```
### ê²°ê³¼
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 14.png>)

```python
plt.figure(figsize=(15, 15))
for i in range(100):
    plt.subplot(10, 10, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_x[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_y[i].argmax()])
plt.show()
```
### ê²°ê³¼
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 15.png>)


# í•˜ì´í¼ íŒŒë¼ë¯¸í„° ë³€ê²½ìœ¼ë¡œ ì„¤ì • ì°¾ì•„ë³´ê¸°

## Case 1: pool_size=(2, 2) -> (1, 1)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 16.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 17.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 18.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 19.png>)

### ë¶„ì„
1. Training and Validation Accuracy (ìƒë‹¨ ê·¸ë˜í”„)

    Training acc (íŒŒë€ìƒ‰ ì ): ì—í¬í¬ê°€ ì§„í–‰ë¨ì— ë”°ë¼ ê¾¸ì¤€íˆ ì¦ê°€í•˜ì—¬ 1.0(100%)ì— ê°€ê¹ê²Œ ë„ë‹¬í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ ë§¤ìš° ì˜ í•™ìŠµí•˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

    Validation acc (íŒŒë€ìƒ‰ ì„ ): ì²˜ìŒì—ëŠ” ì¦ê°€í•˜ë‹¤ê°€ ì•½ 5~7 ì—í¬í¬ ì´í›„ì—ëŠ” ê±°ì˜ ì¦ê°€í•˜ì§€ ì•Šê³ , ì˜¤íˆë ¤ ì•½ê°„ ê°ì†Œí•˜ê±°ë‚˜ ë¶ˆê·œì¹™í•˜ê²Œ ì›€ì§ì´ëŠ” ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤ (ëŒ€ëµ 0.6ì—ì„œ 0.65 ì‚¬ì´). ê·¸ë¦¬ê³  í›ˆë ¨ ì •í™•ë„ì™€ ê²€ì¦ ì •í™•ë„ ì‚¬ì´ì˜ ê°„ê²©ì´ ì ì  ë²Œì–´ì§‘ë‹ˆë‹¤.

2. Training and Validation Loss (í•˜ë‹¨ ê·¸ë˜í”„)

    Training loss (íŒŒë€ìƒ‰ ì ): ì—í¬í¬ê°€ ì§„í–‰ë¨ì— ë”°ë¼ ê¾¸ì¤€íˆ ê°ì†Œí•˜ì—¬ 0ì— ê°€ê¹ê²Œ ë„ë‹¬í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ì˜¤ì°¨ë¥¼ ë§¤ìš° ì˜ ì¤„ì´ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

    Validation loss (íŒŒë€ìƒ‰ ì„ ): ì²˜ìŒì—ëŠ” ê°ì†Œí•˜ë‹¤ê°€ ì•½ 5~7 ì—í¬í¬ ì´í›„ì—ëŠ” ì˜¤íˆë ¤ ì¦ê°€í•˜ê¸° ì‹œì‘í•©ë‹ˆë‹¤. í›ˆë ¨ ì†ì‹¤ê³¼ ê²€ì¦ ì†ì‹¤ ì‚¬ì´ì˜ ê°„ê²©ì´ ê¸‰ê²©íˆ ë²Œì–´ì§€ëŠ” ê²ƒì„ ëª…í™•íˆ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê²°ë¡ : ê³¼ì í•© (Overfitting)

ë‘ ê·¸ë˜í”„ ëª¨ë‘ **ì‹¬ê°í•œ ê³¼ì í•©(Overfitting)**ì´ ë°œìƒí–ˆìŒì„ ëª…í™•íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.

    ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ê±°ì˜ ì™„ë²½í•˜ê²Œ í•™ìŠµí–ˆì§€ë§Œ (ë†’ì€ í›ˆë ¨ ì •í™•ë„, ë‚®ì€ í›ˆë ¨ ì†ì‹¤),

    ì´ì „ì— ë³´ì§€ ëª»í•œ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ì„±ëŠ¥ì´ ì •ì²´ë˜ê±°ë‚˜ ì˜¤íˆë ¤ ë‚˜ë¹ ì§€ê³  ìˆìŠµë‹ˆë‹¤ (ë‚®ì€ ê²€ì¦ ì •í™•ë„, ì¦ê°€í•˜ëŠ” ê²€ì¦ ì†ì‹¤).

ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì˜ ë…¸ì´ì¦ˆë‚˜ íŠ¹ì • íŒ¨í„´ê¹Œì§€ë„ ì•”ê¸°í•˜ì—¬, ì‹¤ì œ ì¼ë°˜í™” ëŠ¥ë ¥ì€ ë–¨ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

## Case2: Filters (32, 64, 64) -> (64, 64, 64)

![alt text](<../../../assets/img/ARM/AI/CNN/image copy 20.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 21.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 22.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 23.png>)

### ë¶„ì„
filters=32 vs filters=64 í•™ìŠµ ê²°ê³¼ ë¹„êµ ë¶„ì„

ë‘ ê²½ìš°ì˜ ì°¨ì´ì  ë° ë¶„ì„

- ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ: í•„í„° ìˆ˜ë¥¼ 32ê°œì—ì„œ 64ê°œë¡œ ëŠ˜ë ¸ìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ëª¨ë¸ì˜ ìµœì¢… ê²€ì¦ ì •í™•ë„ë‚˜ ì†ì‹¤ì´ ìœ ì˜ë¯¸í•˜ê²Œ ê°œì„ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 
- ë‘ ê²½ìš° ëª¨ë‘ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì˜ ê³¼ì í•© ì§•í›„ë¥¼ ë³´ì´ë©°, í›ˆë ¨ê³¼ ê²€ì¦ ì„±ëŠ¥ ê°„ì˜ ê°„ê²©ë„ ê±°ì˜ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤.

- ëª¨ë¸ ë³µì¡ë„ ì¦ê°€ì˜ íš¨ê³¼ ë¯¸ë¯¸: í•„í„° ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ëª¨ë¸ì˜ í‘œí˜„ë ¥ê³¼ í•™ìŠµ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¦ê°€í•˜ì—¬ ë” ë³µì¡í•œ íŠ¹ì§•ì„ í•™ìŠµí•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•˜ì§€ë§Œ, ì´ ê²½ìš°ì—ëŠ” ê·¸ íš¨ê³¼ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

ì´ë¯¸ 32ê°œ í•„í„°ë¡œ ì¶©ë¶„í•œ í‘œí˜„ì„ í•˜ê³  ìˆìœ¼ë©°, ê¸°ì¡´ í•„í„°ë“¤ì´ ì¤‘ë³µë˜ì–´ ë¹„ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Case3: optimizer 'rmsprop' -> 'Adam'
```python
############### Adam #########################

import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10

(train_x, train_y), (test_x, test_y) = cifar10.load_data()

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

train_x = train_x / 255.
test_x = test_x / 255.

from tensorflow.keras.utils import to_categorical

train_y = to_categorical(train_y)
test_y = to_categorical(test_y)

# CNN ëª¨ë¸ ë””ìì¸
from tensorflow.keras import models, layers
from tensorflow.keras.optimizers import Adam # Adam ì˜µí‹°ë§ˆì´ì € ì„í¬íŠ¸

model = models.Sequential()

# (32, 32, 3) => (30, 30, 32)
model.add(layers.Conv2D(filters=32, kernel_size=(3, 3),
                        activation='relu',
                        input_shape=(32, 32, 3)))
# (30, 30, 32) => (15, 15, 32)
model.add(layers.MaxPool2D(pool_size=(2, 2)))

# (15, 15, 32) => (13, 13, 64)
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),
                        activation='relu'))

# (13, 13, 64) => (6, 6, 64)
model.add(layers.MaxPool2D(pool_size=(2, 2)))

# (6, 6, 64) => (4, 4, 64)
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),
                        activation='relu'))

# 3Dë¥¼ 1Dë¡œ ë³€í™˜
model.add(layers.Flatten())

# Classification : Fully Connected Layer ì¶”ê°€
model.add(layers.Dense(units=64, activation='relu'))
model.add(layers.Dense(units=10, activation='softmax'))

# ëª¨ë¸ì˜ í•™ìŠµ ì •ë³´ ì„¤ì •
# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) # ê¸°ì¡´ rmsprop
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Adamìœ¼ë¡œ ë³€ê²½

# ëª¨ë¸ í•™ìŠµ
history = model.fit(x=train_x, y=train_y, epochs=20, batch_size=256, verbose=2, validation_split=0.2)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()
```
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 24.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 25.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 26.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 27.png>)

## ë¶„ì„
ë‘ ì˜µí‹°ë§ˆì´ì €(rmspropê³¼ Adam) ê°„ì˜ í° ì„±ëŠ¥ ì°¨ì´ëŠ” ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.

- ìµœì¢… ì •í™•ë„: í›ˆë ¨ ë° ê²€ì¦ ì •í™•ë„ ëª¨ë‘ rmspropì¼ ë•Œì™€ Adamì¼ ë•Œ ê±°ì˜ ë™ì¼í•œ ìˆ˜ì¤€ (í›ˆë ¨ ì•½ 0.79, ê²€ì¦ ì•½ 0.69)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.

- ì†ì‹¤ ê³¡ì„ : í›ˆë ¨ ì†ì‹¤: Adamì´ rmspropë³´ë‹¤ ì•½ê°„ ë” ë†’ì€ ìµœì¢… í›ˆë ¨ ì†ì‹¤(ì•½ 0.79 vs 0.61)ì„ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” Adamì´ rmspropë§Œí¼ í›ˆë ¨ ë°ì´í„°ì— "ê³¼í•˜ê²Œ" ë§ì¶”ë ¤ í•˜ì§€ ì•ŠëŠ” ê²½í–¥ì´ ìˆë‹¤,

- ê²€ì¦ ì†ì‹¤: Adamì´ rmspropë³´ë‹¤ ì•½ê°„ ë” ë‚®ì€ ìµœì¢… ê²€ì¦ ì†ì‹¤(ì•½ 0.9 vs 0.95-1.0)ì„ ë³´ì…ë‹ˆë‹¤. ë˜í•œ Adamì˜ ê²€ì¦ ì†ì‹¤ ê³¡ì„ ì€ rmspropë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ì¡°ê¸ˆ ë” ì•ˆì •ì ì¸ ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤. íŠ¹íˆ í›„ë°˜ë¶€ì— rmspropì˜ ê²€ì¦ ì†ì‹¤ì´ ë¯¸ë¯¸í•˜ê²Œ ìƒìŠ¹í•˜ê±°ë‚˜ ì •ì²´ëœ ë°˜ë©´, Adamì€ ì•½ê°„ ë” ê¾¸ì¤€íˆ ê°ì†Œí•˜ëŠ” ê²½í–¥ì„ ë³´ì—¬ ê³¼ì í•© ì§•í›„ê°€ ë¯¸ì„¸í•˜ê²Œ ì™„í™”ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Case 4: Drop Out (rate 0.5) + Adam

```python
# Classification : Fully Connected Layer ì¶”ê°€
model.add(layers.Dense(units=64, activation='relu'))
model.add(layers.Dropout(0.5)) # <--- ì—¬ê¸°ì— Dropout ë ˆì´ì–´ ì¶”ê°€ (ì˜ˆì‹œ: rate=0.5)
model.add(layers.Dense(units=10, activation='softmax'))
```
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 28.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 29.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 30.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 31.png>)


### ë¶„ì„

ê³¼ì†Œì í•© (Underfitting):

- ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„° ìì²´ë„ ì¶©ë¶„íˆ í•™ìŠµí•˜ì§€ ëª»í•˜ê³  ìˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. 
  
- í›ˆë ¨ ì •í™•ë„ê°€ 0.65 ìˆ˜ì¤€ì—ì„œ ë©ˆì¶”ê³  í›ˆë ¨ ì†ì‹¤ì´ 0.95 ì •ë„ì— ë¨¸ë¬´ëŠ” ê²ƒì€ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ë¥¼ ì œëŒ€ë¡œ ì•”ê¸°í•˜ì§€ ëª»í–ˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

-ì›ì¸:

    ëª¨ë¸ì˜ ë³µì¡ë„ê°€ ë„ˆë¬´ ë‚®ìŒ: í˜„ì¬ CNN ëª¨ë¸ì˜ ë ˆì´ì–´ ìˆ˜ë‚˜ í•„í„° ìˆ˜ê°€ ë°ì´í„°ì…‹ì˜ ë³µì¡ë„ë¥¼ í•™ìŠµí•˜ê¸°ì— ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ìŒ: í•™ìŠµë¥ ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê°€ ë„ˆë¬´ ë¯¸ë¯¸í•˜ì—¬ ëª¨ë¸ì´ ìµœì ì ì— ë„ë‹¬í•˜ëŠ” ë° ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ê±°ë‚˜ ë„ë‹¬í•˜ì§€ ëª»í•©ë‹ˆë‹¤.

    ì—í¬í¬ ìˆ˜ê°€ ë„ˆë¬´ ì ìŒ: 20 ì—í¬í¬ê°€ ì´ ëª¨ë¸ì´ ìµœì ì ì— ë„ë‹¬í•˜ê¸°ì— ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
 
    ì •ê·œí™”ê°€ ë„ˆë¬´ ê°•í•¨: ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ì„ ë„ˆë¬´ ë†’ê²Œ ì„¤ì •í–ˆê±°ë‚˜, ë‹¤ë¥¸ ê°•ë ¥í•œ ì •ê·œí™” ê¸°ë²•ì„ ì ìš©í–ˆì„ ê²½ìš°, ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ì í•©í•˜ëŠ” ê²ƒì„ ë„ˆë¬´ ê°•í•˜ê²Œ ë§‰ì•„ ê³¼ì†Œì í•©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


## Case5: DropOut rate = 0.5 -> 0.2

![text](<../../../assets/img/ARM/AI/CNN/image copy 32.png>)
![text](<../../../assets/img/ARM/AI/CNN/image copy 33.png>) 
![text](<../../../assets/img/ARM/AI/CNN/image copy 34.png>) 
![text](<../../../assets/img/ARM/AI/CNN/image copy 35.png>)

**ì¬ë¶„ì„**

![alt text](<../../../assets/img/ARM/AI/CNN/image copy 37.png>)
![alt text](<../../../assets/img/ARM/AI/CNN/image copy 36.png>)

### ë¶„ì„
- ëª¨ë¸ì˜ ê³¼ë„í•œ ì •ê·œí™”ë¥¼ ì™„í•˜í•˜ì—¬ í›ˆë ¨ ëŠ¥ë ¥ì„ ê°œì„ í•˜ì—¬ ì „ë°˜ì ì¸ ì„±ëŠ¥(ì •í™•ë„)ë¥¼ í–¥ìƒì‹œí‚¤ë©° ë” ì´ìƒì ì¸ í•™ìŠµ ê³¡ì„  í˜•íƒœë¥¼ ë§Œë“¤ì—ˆë‹¤.
